{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRA_sampler.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCfOEJYvqMljRr5UPgWAkc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emretaylanduman/codes_public/blob/master/SRA_sampler.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45FGjt2-eMh4"
      },
      "source": [
        "from urllib.request import Request, urlopen\n",
        "import re\n",
        "import math\n",
        "import textwrap\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from nucleus.io import fastq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZZ-RjKteajH"
      },
      "source": [
        "dir_hom = 'your_wd' # Set your current wd\n",
        "os.chdir('/home/etd/Desktop/data_set2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86z21wXse2vq"
      },
      "source": [
        "cmd_1 = 'fastq-dump -N'\n",
        "cmd_2 = ' -O ' + dir_hom + ' '"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zLFkJfnfWx5"
      },
      "source": [
        "# Reading downloaded SRR accesion codes.\n",
        "# These accesions flitered and downloaded by RunSelector for spesific purposes. \n",
        "\n",
        "s = 1\n",
        "file = open('SRR_Acc_Hiseq2000_2.txt','r')  #Downladed accession numbers\n",
        "a = file.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1GeTUsUffGP"
      },
      "source": [
        "list_sizes = []\n",
        "# Every file in SRR contains different number of reads.\n",
        "# This lines controls the number of lines in every SRR accesion codes.\n",
        "for i in a:\n",
        "\n",
        "    req = Request('https://trace.ncbi.nlm.nih.gov/Traces/sra/?run='+i)          \n",
        "    name = i[:-1] + '.fastq'\n",
        "    response = urlopen(req)\n",
        "    \n",
        "    lines = []\n",
        "    for line in response:\n",
        "        line=line.decode('utf-8')\n",
        "        lines.append(line)\n",
        "\n",
        "    # Searching from the website data file size thats directly converts to the number of reads    \n",
        "    length = str([x for x in lines if re.search('total_spots', x)])\n",
        "    multip = str([x for x in lines if re.search('file-size', x)])\n",
        "    \n",
        "    \n",
        "    file_len = length[length.find('spots\">')+len('spots\">'):length.rfind('<span class')]\n",
        "    mlyer = multip[multip.find('file-size')+len('file-size '):multip.rfind('</span>bp<')]\n",
        "    \n",
        "    # Check if there are Gigabyte or megabyte size file in focused file.\n",
        "    # Depending on the file size, random number range will be changed\n",
        "\n",
        "    if mlyer[-1]=='G':\n",
        "        num_ofl = float(file_len)*math.pow(10.0,6)\n",
        "    elif mlyer[-1]=='M':\n",
        "        num_ofl = float(file_len)*math.pow(10.0,6)\n",
        "    num_ofl = int(num_ofl)\n",
        "    list_sizes.append(num_ofl)\n",
        "    x = random.sample(range(1, num_ofl), 100)  # Number of reads that will be taken\n",
        "\n",
        "    # For every 100 number from range of the file, download reads and process\n",
        "    for t in x:\n",
        "        cmd =  cmd_1 +' ' + str(t) + ' -X ' + str(t+1) + cmd_2 + i[:-1]\n",
        "        cm_d = 'cat *.fastq >> sampled.all'    # Downloaded reads concatanated\n",
        "        os.system(cmd)\n",
        "        os.system(cm_d)\n",
        "        print('Sampled\\n')\n",
        "        if name in os.listdir(dir_hom):        # Check if the file downladed without problem\n",
        "            print('\\nDownloaded ' + i + '.fastq\\n')\n",
        "            print('Processing...\\n')\n",
        "           \n",
        "            seq_err = []\n",
        "            qual_err = []\n",
        "            new_words = []\n",
        "            new_words2 = []            \n",
        "            with fastq.FastqReader(name) as reader:\n",
        "                for record in reader:\n",
        "                    seq_err = record.sequence\n",
        "                    qual_err = record.quality\n",
        "                new_word = ''\n",
        "                for k in range(len(record.sequence)):\n",
        "                    location = str(k)\n",
        "                    new_word = new_word + location + seq_err[k] + qual_err[k] + ' '\n",
        "                    new_word2 = new_word + seq_err[k] + qual_err[k] + ' '                    \n",
        "                new_words.append(new_word)\n",
        "                new_words2.append(new_word2)\n",
        "            \n",
        "            mer3_seq = textwrap.wrap(record.sequence,3)\n",
        "            mer3_qual = textwrap.wrap(record.quality,3)\n",
        "            with open('sampled_genome_all.txt', 'a+') as f:\n",
        "                for item in new_word:\n",
        "                    f.write(\"%s\\n\" % item)\n",
        "\n",
        "            with open('sampled_without_loc.txt', 'a+') as f:\n",
        "                for item2 in new_word2:\n",
        "                    f.write(\"%s\\n\" % item2)\n",
        "                print(s)                \n",
        "#            with open('sampled_5mer_seq.txt', 'a+') as j:\n",
        "#                for seq in mer5_seq:\n",
        "#                    if len(seq)==5:\n",
        "#                        j.write(\"%s \" % seq)\n",
        "#                j.write(\"\\n\")\n",
        "#            with open('sampled_5mer_qual.txt', 'a+') as k:\n",
        "#                for qual in mer5_qual:\n",
        "#                    if len(qual)==5:\n",
        "#                        k.write(\"%s \" % qual)\n",
        "#                k.write(\"\\n\")\n",
        "#    \n",
        "            with open('sampled_3mer_seq.txt', 'a+') as j:\n",
        "                for seq in mer3_seq:\n",
        "                    if len(seq)==3:\n",
        "                        j.write(\"%s \" % seq)\n",
        "                j.write(\"\\n\")\n",
        "                print('Seq Written\\n')\n",
        "            with open('sampled_3mer_qual.txt', 'a+') as k:\n",
        "                for qual in mer3_qual:\n",
        "                    if len(qual)==3:\n",
        "                        k.write(\"%s \" % qual)\n",
        "                k.write(\"\\n\")\n",
        "    \n",
        "                print('Qual Written\\n')\n",
        "                \n",
        "            s=s+1\n",
        "            os.remove(name)\n",
        "            f.close()\n",
        "            j.close()\n",
        "            k.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}